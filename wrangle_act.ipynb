{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling on WeRateDogs\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Gather](#gather)\n",
    "- [Assess](#assess)\n",
    "- [Clean](#clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "The main purpose of this project is to put into practice key concepts learnt during this module. Tasks that will be carrier out on the following notebook are gathering, assessing and cleaning data that has been provided to us using different means. In order to do so Python 3 will be used. Also the solution provided will lean on the following set of python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "## Gather    \n",
    "\n",
    "The first step in data analysis is data gathering. In this case data gathering will be comprised of the following steps:   \n",
    "**1.-** Import the tweeter archive for WeRateDogs into the workspace   \n",
    "**2.-** Download image predictions data from a given URL   \n",
    "**3.-** Gather data from the Tweeter API to collect more relevant information   \n",
    "\n",
    "#### 1.- Import the tweeter archive\n",
    "This file has already been provided as a manual download. As such, it's available locally and just need to import it using pandas read_csv method for reading flat files into a pandas dataframe. Then, output the first row to verify that it has loaded successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df = pd.read_csv(\"twitter_archive_enhanced.csv\")\n",
    "archive_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.- Download image predictions data from a given URL   \n",
    "Unlike the previous file, in this case the file's URL was given. Hence, we download the file programatically as this is less prone to errors and eases reproducibility.    \n",
    "First download the file using python library **_requests_** and save the information downloaded in a file. Then, import the file similarly to how it was done in step \\#1. Also output first row to verify everything has gone correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog      p2   p2_conf  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True  collie  0.156665   \n",
       "\n",
       "   p2_dog                 p3   p3_conf  p3_dog  \n",
       "0    True  Shetland_sheepdog  0.061428    True  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "image_predictions = requests.get(url)\n",
    "file_name = url.split('/')[-1]\n",
    "with open(file_name, mode='w', encoding =image_predictions.encoding) as f:\n",
    "    f.write(image_predictions.text)\n",
    "image_df = pd.read_csv(file_name,sep='\\t')\n",
    "image_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.- Gather data from Tweeter by accessing their API \n",
    "The third step for this data gathering effort is to obtain various pieces of data from Tweeter directly by using their API. Please note that keys and tokens are stored in a separate file that is stored locally and is not part of source control. As such, these fields will need to be edited if this notebook was to used different tweeter app credentials.    \n",
    "The idea is to query Tweeter's API through python's api library for tweeter (Tweepy). The idea is to get some more information for each of the tweets we have in df_archive dataframe. Then store json content into a txt file. Once the json text file is available parse it and create a new dataframe to work under python environment. \n",
    "So let's first define the function that will be used to parse json text file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJson():\n",
    "    jsonlist = []\n",
    "    with open('tweet_json.txt','r',encoding='utf-8') as fjsonRead:\n",
    "        for line in fjsonRead:\n",
    "            json_dict = json.loads(line)\n",
    "            tweet_id = json_dict['id']\n",
    "            retw_count = json_dict['retweet_count']\n",
    "            fav_count = json_dict['favorite_count']\n",
    "            jsonlist.append({'tweet_id':tweet_id, 'retw_count':retw_count, 'fav_count':fav_count})\n",
    "    return pd.DataFrame(jsonlist,columns=['tweet_id', 'retw_count', 'fav_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading information from the API for so many tweets it's a time consuming task. Thus, we would not like to do it every time this notebook is run since this operation can take 30 minutes on its own. Therefore if the file is present, it's assumed that the API has already been queried and data stored in the file. If this was the case, then proceed with parsing the file into a dataframe. Otherwise, query the API and store data in a text file before parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retw_count</th>\n",
       "      <th>fav_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>8366</td>\n",
       "      <td>38195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  retw_count  fav_count\n",
       "0  892420643555336193        8366      38195"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    tweeter_df = parseJson()\n",
    "except FileNotFoundError as e:\n",
    "    start = timer()\n",
    "    with open('tweet_json.txt','w',encoding='utf-8') as f:\n",
    "        with open('tweetIdsFailed.txt','w',encoding='utf-8') as ffail:\n",
    "            with open('tweeterKeys.txt','r',encoding='utf-8') as f:\n",
    "                getData = lambda line: line.split(' ')[0]\n",
    "                consumer_key = getData(f.readline())\n",
    "                consumer_secret = getData(f.readline())\n",
    "                access_token = getData(f.readline())\n",
    "                access_secret = getData(f.readline())\n",
    "                auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "                auth.set_access_token(access_token, access_secret)\n",
    "                api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "                for row in archive_df['tweet_id']:\n",
    "                    try:\n",
    "                        tweet = api.get_status(row,tweet_mode='extended')\n",
    "                        json.dump(tweet._json, f)\n",
    "                        f.write('\\n')\n",
    "                    except tweepy.TweepError as e:\n",
    "                        ffail.write(str(row)+'\\n')\n",
    "    end = timer()\n",
    "    print('Time: {}'.format(end-start))\n",
    "    tweeter_df = parseJson()\n",
    "tweeter_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all data has been collected, we need to inspect each dataframe to find flaws in either contents or structure. Let's start with archive_df. Let's first have a general look by printing the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information above is filtered data from the 5000+ Tweeter account. It's filtered taking into account only those tweets that contain dog ratings. However as it can be seen above some of the tweets are **re**tweets and so we can regard these as duplicated information. We could verify that **retweeted_status_id** == tweet_id for other row in the dataframe. The problem here is that the type for column retweeted_status_id is float64. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.874739571039519e+17 887473957103951872\n"
     ]
    }
   ],
   "source": [
    "print (archive_df[archive_df['retweeted_status_id'].notnull()].retweeted_status_id.values[0],\n",
    "       archive_df[archive_df['retweeted_status_id'].notnull()].retweeted_status_id.astype('int64').values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To me the above results are wrong. The number on the left, in floating point arithmetic, contains only 15 decimal digits. The exponent however indicates 17. Therefore when casting to an **int64** type, somehow the last two digits are made up...\n",
    "# ASK ABOUT THIS BEHAVIOR\n",
    "Therefore and unless this data is gathered it's impossible to verify whether all retweets are already contained in the archive_df in the form of normal tweets. At this point there are two options. \n",
    "> First, search for this missing information in the downloaded json file\n",
    "> Or second, assumme that all retweets' information is already present in archive_df in the form of normal tweets\n",
    "\n",
    "Let's take the first option. This also demonstrates the spirit of iteration for which there was much emphasis in the class. Let's first create a new column called **retweeted_status_id_2** that will contain the integer retweeted_id. This column will be in string format and so no information will be lost. Then, we will compare both retweeted_status_id with retweeted_status_id2 to verify that they are not the same. Let's _gather_ the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweet id for which the tweet was a retweet\n",
    "retw = archive_df[archive_df['retweeted_status_id'].notnull()].tweet_id.values\n",
    "archive_df['retweeted_status_id_2'] = np.NaN\n",
    "with open('tweet_json.txt','r',encoding='utf-8') as fjsonRead:\n",
    "    for line in fjsonRead:\n",
    "        json_dict = json.loads(line)\n",
    "        if json_dict['id'] in retw:\n",
    "            archive_df.loc[archive_df[archive_df['tweet_id']==json_dict['id']].index,'retweeted_status_id_2'] = str(json_dict['retweeted_status']['id'])\n",
    "        else:\n",
    "            archive_df.loc[archive_df[archive_df['tweet_id']==json_dict['id']].index,'retweeted_status_id_2'] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the information has been collected, let's compare both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0, -1, -3,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,\n",
       "       -2,  0,  0,  0,  0,  0, -2, -1,  0, -1,  0, -2, -1, -1, -2,  0,  0,\n",
       "        0, -2, -3, -2,  0, -2,  0,  0, -1, -1,  0,  0, -5, -1, -2, -1,  0,\n",
       "        0,  0,  0,  0, -4, -5,  0,  0,  0,  0,  0,  0,  0, -2,  0,  0, -4,\n",
       "        0,  0,  0, -2,  0,  0, -1, -2,  0,  0,  0,  0,  0,  0,  0,  0, -2,\n",
       "        0, -1,  0,  0,  0,  0,  0, -5,  0,  0,  0,  0,  0,  0, -4,  0,  0,\n",
       "        0,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0, -1,  0,  0, -5,  0,\n",
       "        0, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,\n",
       "       -1,  0, -2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -2,\n",
       "        0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retw = archive_df[archive_df['retweeted_status_id_2'].notnull()]\n",
    "(retw.retweeted_status_id.astype('int64') - retw.retweeted_status_id_2.astype('int64')).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results above. They indicate that the casting from float to int64 does not yield correct results and so it would have been wrong to analyse using a casting method. Therefore the information needs to be extracted from the API itself. Now that we have the right information let's see how many of these retweets are already present in the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.isin(retw.retweeted_status_id_2.astype('int64').values,archive_df.tweet_id.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen by the number 145 above that some entries in the archive_df are duplicates of original tweets.    \n",
    "> **Some retweets contain duplicate information**     \n",
    "\n",
    "Also mentioned above, some column types are wrong. Columns that are id(s) should not be float64. Also timestamp columns should be casted to datetime\n",
    "> **Some column types are wrong**\n",
    "\n",
    "In a similar way, when this twitter account replied to some tweets it's possible that both original and reply contain a score. In this case the second one overrides the first and so we should only consider the last score to be the valid one. Let's proceed as we did for the retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message:\n",
      "    This is Pipsy. He is a fluffball. Enjoys traveling the sea &amp; getting tangled in leash. 12/10 I would kill for Pipsy https://t.co/h9R0EwKd9X\n",
      "In reply to the previous\n",
      "    Ladies and gentlemen... I found Pipsy. He may have changed his name to Pablo, but he never changed his love for the sea. Pupgraded to 14/10 https://t.co/lVU5GyNFen\n",
      "Total number of replies for which the original is in archive_df : 44\n"
     ]
    }
   ],
   "source": [
    "# Get tweet id for which the tweet was a retweet\n",
    "retw = archive_df[archive_df['in_reply_to_status_id'].notnull()].tweet_id.values\n",
    "archive_df['in_reply_to_status_id_2'] = np.NaN\n",
    "with open('tweet_json.txt','r',encoding='utf-8') as fjsonRead:\n",
    "    for line in fjsonRead:\n",
    "        json_dict = json.loads(line)\n",
    "        if json_dict['id'] in retw:\n",
    "            if str(json_dict['in_reply_to_status_id']) == 'None':\n",
    "                archive_df.loc[archive_df[archive_df['tweet_id']==json_dict['id']].index,'in_reply_to_status_id'] = np.NaN\n",
    "                archive_df.loc[archive_df[archive_df['tweet_id']==json_dict['id']].index,'in_reply_to_user_id'] = np.NaN\n",
    "            else:\n",
    "                archive_df.loc[archive_df[archive_df['tweet_id']==json_dict['id']].index,'in_reply_to_status_id_2'] = str(json_dict['in_reply_to_status_id'])\n",
    "        else:\n",
    "            archive_df.loc[archive_df[archive_df['tweet_id']==json_dict['id']].index,'in_reply_to_status_id_2'] = np.NaN  \n",
    "retw = archive_df[archive_df['in_reply_to_status_id_2'].notnull()]\n",
    "print('Original message:')\n",
    "print('    {}'.format( archive_df.loc[archive_df.tweet_id == np.int64(retw.iloc[5].in_reply_to_status_id_2)].text.values[0]))\n",
    "print('In reply to the previous')\n",
    "print('    {}'.format(retw.iloc[5].text))\n",
    "numberreplies = sum(np.isin(retw.in_reply_to_status_id_2.astype('int64').values,archive_df.tweet_id.values))\n",
    "print('Total number of replies for which the original is in archive_df : {}'.format(numberreplies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above that there are 44 replies that need to be removed\n",
    "> **Some replies contain duplicated score**\n",
    "\n",
    "Coming back to archive_df.info(), it can be observed that some of the values in expanded_url are missing. This information needs to be gathered\n",
    "> **Expanded_url column contains missing information**\n",
    "\n",
    "Let's now check what happens with dog names. I guess that a regex statement has been used to extract dog names on this column. It's possible that the standard regex may extract wrong information, so let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['None', 'a', 'Charlie', 'Cooper', 'Lucy', 'Oliver', 'Lola', 'Tucker',\n",
      "       'Penny', 'Winston', 'Bo', 'the', 'Sadie', 'an', 'Toby', 'Buddy',\n",
      "       'Bailey', 'Daisy', 'Jax', 'Stanley', 'Leo', 'Dave', 'Jack', 'Rusty',\n",
      "       'Milo', 'Oscar', 'Koda', 'Scout', 'Bella', 'Alfie', 'Bentley', 'Gus',\n",
      "       'Larry', 'Sunny', 'George', 'Phil', 'Chester', 'very', 'Sammy',\n",
      "       'Louis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(archive_df.name.value_counts().index[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed above that **a,** **an**, **very**, **the** ... are not real dog names. Also there is a huge number of missing names. From what I can see above, it seems that most errors share a similar pattern, that is the first letter is in lowercase, as opposed to proper names.\n",
    "Let's develop this idea a bit further\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quite</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mad</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>getting</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>officially</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incredibly</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infuriating</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacceptable</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name\n",
       "a               55\n",
       "the              8\n",
       "an               7\n",
       "very             5\n",
       "quite            4\n",
       "just             4\n",
       "one              4\n",
       "mad              2\n",
       "getting          2\n",
       "not              2\n",
       "actually         2\n",
       "officially       1\n",
       "his              1\n",
       "space            1\n",
       "my               1\n",
       "light            1\n",
       "by               1\n",
       "this             1\n",
       "incredibly       1\n",
       "old              1\n",
       "infuriating      1\n",
       "all              1\n",
       "life             1\n",
       "unacceptable     1\n",
       "such             1"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = pd.DataFrame(archive_df.name.value_counts())\n",
    "names.loc[[x.islower() for x in archive_df.name.value_counts().index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems clear that _name_ column requires some cleaning\n",
    "> **Some names are not real pet names**\n",
    "\n",
    "Also, I'm quite intrigued to know what does the source column represent. Loooking at tweeter's [api documentation](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html). Source gives information as to where data has been originated. Let's have a look at the values that this column takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2221\n",
       "<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\n",
       "<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       33\n",
       "<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that for this dataframe sample, only four values are possible. It can be therefore regarded as categorical data instead of the awful way with which this information is represented. Let's clean this column so categories are clearer when looking at this dataframe\n",
    "> **Source column contains categories in XML format**\n",
    "\n",
    "What about the ratings, we know the denominator needs to be always 10, but is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.356000e+03</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>2356.000000</td>\n",
       "      <td>2356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.427716e+17</td>\n",
       "      <td>7.440692e+17</td>\n",
       "      <td>2.040329e+16</td>\n",
       "      <td>7.720400e+17</td>\n",
       "      <td>1.241698e+16</td>\n",
       "      <td>13.126486</td>\n",
       "      <td>10.455433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.856705e+16</td>\n",
       "      <td>7.524295e+16</td>\n",
       "      <td>1.260797e+17</td>\n",
       "      <td>6.236928e+16</td>\n",
       "      <td>9.599254e+16</td>\n",
       "      <td>45.876648</td>\n",
       "      <td>6.745237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.660209e+17</td>\n",
       "      <td>6.658147e+17</td>\n",
       "      <td>1.185634e+07</td>\n",
       "      <td>6.661041e+17</td>\n",
       "      <td>7.832140e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.783989e+17</td>\n",
       "      <td>6.757073e+17</td>\n",
       "      <td>3.589728e+08</td>\n",
       "      <td>7.186315e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.196279e+17</td>\n",
       "      <td>7.032559e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>7.804657e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.993373e+17</td>\n",
       "      <td>8.233264e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>8.203146e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.924206e+17</td>\n",
       "      <td>8.862664e+17</td>\n",
       "      <td>8.405479e+17</td>\n",
       "      <td>8.874740e+17</td>\n",
       "      <td>7.874618e+17</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "count  2.356000e+03           7.700000e+01         7.700000e+01   \n",
       "mean   7.427716e+17           7.440692e+17         2.040329e+16   \n",
       "std    6.856705e+16           7.524295e+16         1.260797e+17   \n",
       "min    6.660209e+17           6.658147e+17         1.185634e+07   \n",
       "25%    6.783989e+17           6.757073e+17         3.589728e+08   \n",
       "50%    7.196279e+17           7.032559e+17         4.196984e+09   \n",
       "75%    7.993373e+17           8.233264e+17         4.196984e+09   \n",
       "max    8.924206e+17           8.862664e+17         8.405479e+17   \n",
       "\n",
       "       retweeted_status_id  retweeted_status_user_id  rating_numerator  \\\n",
       "count         1.810000e+02              1.810000e+02       2356.000000   \n",
       "mean          7.720400e+17              1.241698e+16         13.126486   \n",
       "std           6.236928e+16              9.599254e+16         45.876648   \n",
       "min           6.661041e+17              7.832140e+05          0.000000   \n",
       "25%           7.186315e+17              4.196984e+09         10.000000   \n",
       "50%           7.804657e+17              4.196984e+09         11.000000   \n",
       "75%           8.203146e+17              4.196984e+09         12.000000   \n",
       "max           8.874740e+17              7.874618e+17       1776.000000   \n",
       "\n",
       "       rating_denominator  \n",
       "count         2356.000000  \n",
       "mean            10.455433  \n",
       "std              6.745237  \n",
       "min              0.000000  \n",
       "25%             10.000000  \n",
       "50%             10.000000  \n",
       "75%             10.000000  \n",
       "max            170.000000  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that denominator includes at least one vlaue of 170. Also a value of 0. This is wrong as we expect all denominators to be 10. Let's see what is the text for those denominators != 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@jonnysun @Lin_Manuel ok jomny I know you're excited but 960/00 isn't a valid rating, 13/10 is tho\",\n",
       "       '@docmisterio account started on 11/15/15',\n",
       "       'The floofs have been released I repeat the floofs have been released. 84/70 https://t.co/NIYC820tmd',\n",
       "       'Meet Sam. She smiles 24/7 &amp; secretly aspires to be a reindeer. \\nKeep Sam smiling by clicking and sharing this link:\\nhttps://t.co/98tB8y7y7t https://t.co/LouL5vdvxx',\n",
       "       'RT @dog_rates: After so many requests, this is Bretagne. She was the last surviving 9/11 search dog, and our second ever 14/10. RIP https:/…'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df[ archive_df['rating_denominator'] != 10 ].text.values[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a few issues with the denominator that we will need to address in the cleaning stage. Also the numerator seems to showcast similar stats, let's see a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['This is Bella. She hopes her smile made you smile. If not, she is also offering you her favorite monkey. 13.5/10 https://t.co/qjrljjt948',\n",
       "       '@dhmontgomery We also gave snoop dogg a 420/10 but I think that predated your research',\n",
       "       '@s8n You tried very hard to portray this good boy as not so good, but you have ultimately failed. His goodness shines through. 666/10',\n",
       "       \"This is Jerry. He's doing a distinguished tongue slip. Slightly patronizing tbh. You think you're better than us, Jerry? 6/10 hold me back https://t.co/DkOBbwulw1\",\n",
       "       '@markhoppus 182/10'], dtype=object)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df[ (archive_df['rating_numerator'] > 20) | (archive_df['rating_numerator'] < 10)].text.values[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerator is harder to clean... sometimes it's not clear whether it was a typing error or an intentional high or low score... However instances like the first one that contains decimal numbers are not properly parsed and needs fixing\n",
    "> **Denominator column contains non 10 values**\n",
    "\n",
    "> **Numerator has not been properly parsed in some cases**\n",
    "\n",
    "Also when looking at dog categories, it can be seen that data is **messy**. We find that there are four columns that can be grouped into one as they are referring to the same variable.\n",
    "> **Archive_df contains messy dog category data**\n",
    "\n",
    "Let's now have a look at the second dataframe, that is image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's fair to say that this dataframe shows issues with structure. p1, p2 and p3 refer to the same variable. The same applies to pX_conf and pX_dog where X in [1,2,3]. Therefore this dataframe needs cleaning\n",
    "> **Same variable spread across a few columns**\n",
    "\n",
    "Also, why are there columns that indicate whether the prediction is a dog or not. Let's have a look at what happens when some of these are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>666051853826850816</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5KoJ1WoAAJash.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>box_turtle</td>\n",
       "      <td>0.933012</td>\n",
       "      <td>False</td>\n",
       "      <td>mud_turtle</td>\n",
       "      <td>0.045885</td>\n",
       "      <td>False</td>\n",
       "      <td>terrapin</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>666055525042405380</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5N9tpXIAAifs1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>chow</td>\n",
       "      <td>0.692517</td>\n",
       "      <td>True</td>\n",
       "      <td>Tibetan_mastiff</td>\n",
       "      <td>0.058279</td>\n",
       "      <td>True</td>\n",
       "      <td>fur_coat</td>\n",
       "      <td>0.054449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>666057090499244032</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5PY90WoAAQGLo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>shopping_cart</td>\n",
       "      <td>0.962465</td>\n",
       "      <td>False</td>\n",
       "      <td>shopping_basket</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>False</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>666104133288665088</td>\n",
       "      <td>https://pbs.twimg.com/media/CT56LSZWoAAlJj2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>hen</td>\n",
       "      <td>0.965932</td>\n",
       "      <td>False</td>\n",
       "      <td>cock</td>\n",
       "      <td>0.033919</td>\n",
       "      <td>False</td>\n",
       "      <td>partridge</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>666268910803644416</td>\n",
       "      <td>https://pbs.twimg.com/media/CT8QCd1WEAADXws.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>desktop_computer</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>False</td>\n",
       "      <td>desk</td>\n",
       "      <td>0.085547</td>\n",
       "      <td>False</td>\n",
       "      <td>bookcase</td>\n",
       "      <td>0.079480</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                          jpg_url  \\\n",
       "6   666051853826850816  https://pbs.twimg.com/media/CT5KoJ1WoAAJash.jpg   \n",
       "7   666055525042405380  https://pbs.twimg.com/media/CT5N9tpXIAAifs1.jpg   \n",
       "8   666057090499244032  https://pbs.twimg.com/media/CT5PY90WoAAQGLo.jpg   \n",
       "17  666104133288665088  https://pbs.twimg.com/media/CT56LSZWoAAlJj2.jpg   \n",
       "18  666268910803644416  https://pbs.twimg.com/media/CT8QCd1WEAADXws.jpg   \n",
       "\n",
       "    img_num                p1   p1_conf  p1_dog               p2   p2_conf  \\\n",
       "6         1        box_turtle  0.933012   False       mud_turtle  0.045885   \n",
       "7         1              chow  0.692517    True  Tibetan_mastiff  0.058279   \n",
       "8         1     shopping_cart  0.962465   False  shopping_basket  0.014594   \n",
       "17        1               hen  0.965932   False             cock  0.033919   \n",
       "18        1  desktop_computer  0.086502   False             desk  0.085547   \n",
       "\n",
       "    p2_dog                p3   p3_conf  p3_dog  \n",
       "6    False          terrapin  0.017885   False  \n",
       "7     True          fur_coat  0.054449   False  \n",
       "8    False  golden_retriever  0.007959    True  \n",
       "17   False         partridge  0.000052   False  \n",
       "18   False          bookcase  0.079480   False  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df[ (image_df['p1_dog'] == False) | (image_df['p2_dog'] == False) | (image_df['p3_dog'] == False) ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some of the images are either not a dog, or contain an object which is not a dog, or the algorithm prediction is wrong. In either case, and since we are dealing with data that relates to dogs, then I think it's cleaner to have data with dogs-only predictions\n",
    "> **Some predictions are not dogs**\n",
    "\n",
    "As for the last dataframe tweeter_df it belongs to the same observational unit as archive_df so we should _join_ both of them\n",
    "> **Twitter_df same observational unit as archive_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "- Some retweets contain duplicate information\n",
    "- Some column types are wrong (IDs are floats. Timestamps are strings)\n",
    "- Some replies contain duplicate information\n",
    "- Expanded_urls contain missing information\n",
    "- Some names are not pet names\n",
    "- Denominator contains non 10 values\n",
    "- Numerator parsing is not entirely correct\n",
    "- Some predictions are not dogs\n",
    "- Source column contains categories in XML format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness\n",
    "- Dog category is messy\n",
    "- Image_df same variable uses a few columns\n",
    "- Twitter_df belongs to the same observational unit as archive_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='clean'></a>\n",
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the required information has been collected via Tweeter API, then we need to join it with data in archive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df = archive_df.merge(df_tweeter,on='tweet_id',how='left')\n",
    "archive_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
